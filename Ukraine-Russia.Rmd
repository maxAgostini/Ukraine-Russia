---
title: "Ukraine-Russia"
author: "Maximilian Agostini, Tasja Mueller, Ben Guetzkow, Pontus Leander, Jannis Kreienkamp"
date: "3/3/2022"
output:
  html_document:
    code_folding: hide
    mathjax: default
    theme: united
    toc: yes
    toc_float: yes
    number_sections: TRUE
    fig_width: 12
    fig_height: 10
    fig_align: center
  pdf_document:
    toc: yes
---

<style type="text/css">
.main-container {
  max-width: 1200px;
  margin-left: auto;
  margin-right: auto;
}
</style>

```{r setup, include=FALSE}
cat("\014") # clear console
rm(list=ls()) # clear workspace
gc # garbage collector

require(pacman)
p_load(tidyr, dplyr, psych, tidytext, ggplot2, reshape2, plyr, stringr, mclust, tictoc, fpc, factoextra, apcluster, clValid, vegan)
library(kluster) # installed from devtools::install_github("hestiri/kluster")

source("./funcs/fun.panel.R") #load relevant functions
set.seed(52) # set overall random seed for reproducibility
```

# Load Data
```{r LoadRawBase, echo=T, warning=F, message=F}
# Import Data
dtRaw <- haven::read_spss("M:/.00 Research/Datasets/Ukraine+Russia_March+5,+2022_17.sav")
```

# Prepare Data
## Cleaning (not collected)
```{r}
tmp <- dtRaw

# exclude practice trials (before we launched on MTurk which was at 2022-02-25 01:42:04)
tmp$StartDate <- as.POSIXct(tmp$StartDate)
tmp <- tmp[tmp$StartDate > as.POSIXct("2022-02-25 01:40:00", tz = "UTC"),]

# exclude participants that did not get to the informed consent (ethics)
tmp <- tmp[tmp$Progress > 95,]
paste("We collected a total of", nrow(tmp), "participants.", sep = " ")

df <- tmp; rm(tmp, dtRaw)
raw <- df
```

## Cleaning (data quality)
```{r}
# identify duplicate IPs (but only the second entry! we keep the first one)
dupli <- df[duplicated(df$IPAddress),]
paste("We removed", nrow(dupli), "entries for entering the study from the same IP (difficult to establish independence of measurements).", sep = " ")
df <- df[!duplicated(df$IPAddress),]
raw$clean_IP <- ifelse(raw$ResponseId %in% dupli$ResponseId, 1, 0); rm(dupli)

# identify duplicate MTurkIds (but only the second entry! we keep the first one)
dupli <- df[duplicated(df$mTurkID),]
paste("We removed", nrow(dupli), "entries for entering the same MTurkId (difficult to establish independence of measurements).", sep = " ")
df <- df[!duplicated(df$mTurkID),]
raw$clean_MTurk <- ifelse(raw$ResponseId %in% dupli$ResponseId, 1, 0); rm(dupli)

# check for straightliner on SDO
  # isolate respondents who have straightlined outside a the median categories (b/c all "neither agree nor disagree" might be meaningful response) 
  strLine <- df %>%
    dplyr::select(ResponseId, SDO_01, SDO_02, SDO_03, SDO_04) %>%
    na.omit() %>% # remove people who have missing data on one of the three items
    mutate(mean = rowMeans(dplyr::select(., contains("SDO"))), 
           sd = matrixStats::rowSds(as.matrix(dplyr::select(., contains("SDO"))))) # calculate row-means and row-sds 
  
  strLine <- strLine %>%
    filter(sd < 1, mean < 4.5 | mean > 6.5) # sd < 0.6 or < 1 would also work
  paste("We removed", nrow(strLine), "entries for straighlining on the SDO scale.", sep = " ")
  # remove straightliners
    df <- df %>%
      filter(!ResponseId %in% strLine$ResponseId)
    raw$clean_SDO <- ifelse(raw$ResponseId %in% strLine$ResponseId, 1, 0); rm(strLine)

# check for straightliner on Locomotion
  # isolate respondents who have straightlined outside a the median categories (b/c all "neither agree nor disagree" might be meaningful response) 
  strLine <- df %>%
    dplyr::select(ResponseId, Loc_Ass_01, Loc_Ass_03, Loc_Ass_04, Loc_Ass_05, Loc_Ass_08, Loc_Ass_12, Loc_Ass_14, Loc_Ass_17, Loc_Ass_19, Loc_Ass_20, Loc_Ass_22, Loc_Ass_23) %>%
    na.omit() %>% # remove people who have missing data on one of the items
    mutate(mean = rowMeans(dplyr::select(., contains("Loc_Ass_"))), 
           sd = matrixStats::rowSds(as.matrix(dplyr::select(., contains("Loc_Ass_"))))) # calculate row-means and row-sds 
  
  strLine <- strLine %>%
    filter(sd < 1, mean < 2.5 | mean > 4.5) # sd < 0.5 or < 0.1 would also work
  paste("We removed", nrow(strLine), "entries for straighlining on the Locomotion scale.", sep = " ")
  # remove straightliners
    df <- df %>%
      filter(!ResponseId %in% strLine$ResponseId)
    raw$clean_Ass <- ifelse(raw$ResponseId %in% strLine$ResponseId, 1, 0); rm(strLine)

# check for straightliner on Assessment
  # isolate respondents who have straightlined outside a the median categories (b/c all "neither agree nor disagree" might be meaningful response) 
  strLine <- df %>%
    dplyr::select(ResponseId, Loc_Ass_02, Loc_Ass_06, Loc_Ass_07, Loc_Ass_09, Loc_Ass_10, Loc_Ass_11, Loc_Ass_13, Loc_Ass_15, Loc_Ass_16, Loc_Ass_18, Loc_Ass_21,  Loc_Ass_24) %>%
    na.omit() %>% # remove people who have missing data on one of the items
    mutate(mean = rowMeans(dplyr::select(., contains("Loc_Ass_"))), 
           sd = matrixStats::rowSds(as.matrix(dplyr::select(., contains("Loc_Ass_"))))) # calculate row-means and row-sds 
  
  strLine <- strLine %>%
    filter(sd < 1, mean < 2.5 | mean > 4.5) # sd < 0.5 or < 0.1 would also work
  paste("We removed", nrow(strLine), "entries for straighlining on the Locomotion scale.", sep = " ")
  # remove straightliners
    df <- df %>%
      filter(!ResponseId %in% strLine$ResponseId)
    raw$clean_Loc <- ifelse(raw$ResponseId %in% strLine$ResponseId, 1, 0); rm(strLine)
    
raw$clean_all <- raw %>%
  select(contains("clean")) %>%
  rowSums()

```

### kluster package
(c) https://github.com/hestiri/kluster/blob/master/vignettes/demo.Rmd
#### plot before klustering
```{r}
tmp <- raw %>%
  select(SDO_01, SDO_03)
raw$SDO_pos <- scoreItems(keys = c(1,1), items = tmp, min = min(tmp[1]), max = max(tmp[1]))$scores; rm(tmp) 
tmp <- raw %>%
  select(SDO_02, SDO_04)
raw$SDO_neg <- scoreItems(keys = c(1,1), items = tmp, min = min(tmp[1]), max = max(tmp[1]))$scores; rm(tmp)
raw$clean_SDO <- factor(raw$clean_SDO, levels = c(0,1), labels = c("no", "yes"))

ggplot(dat)+
  geom_point(data = raw, aes(x=SDO_pos, y= SDO_neg,colour=clean_SDO),size=3,alpha=0.3)+
  ggtitle("") +
  theme_bw() +
  theme(panel.grid.major.y = element_line(colour = "gray"),
        panel.grid.minor.y = element_blank(),
        axis.line = element_line(size=0.5, colour = "black"),
        panel.border = element_blank(), panel.background = element_blank(),
        plot.title = element_text(size = 14, face = "bold"),
        text=element_text(face = "bold"),
        axis.text.x=element_text(colour="black", size = 10, face="plain"),
        axis.text.y=element_text(colour="black", size = 10, face="plain"),
        legend.position="bottom")

```
#### run kluster
In a first step we simply run the kluster to get the most likely number of clusters in the data. We use BIC and PAMK as those are the ones that most often seem to get close.
```{r}
tmp <- raw %>%
  dplyr::select(SDO_01, SDO_02, SDO_03, SDO_04)

iter_klust <- 50
smpl <- 100

# Bayesian Information Criterion clustering
out_kluster_BIC <- kluster::kluster(data = tmp,
                                iter_klust = iter_klust, # can also be ignored and recommended will be used
                                smpl = smpl, # can also be ignored and recommended will be used
                                algorithm = "BIC") # specify or will crush with large sample

# Partitioning Around Medoids clustering
out_kluster_PAMK <- kluster::kluster(data = tmp,
                                iter_klust = iter_klust, # can also be ignored and recommended will be used
                                smpl = smpl, # can also be ignored and recommended will be used
                                algorithm = "PAMK") # specify or will crush with large sample

```

#### evaluate kluster
We then evaluate the kluster to a specific number of expected cluster (in our case two: straightliners and non-straightliners):
- e_mean and e_freq represent the respective error terms for the mean and most frequent `kluster` products on each algorithms.  
- k_mean and k_freq the mean and most frequent kluster products
- ptime is the processing time
(we do not need the cluster_sim function as we are not interested in the original algorithms)
```{r}
eval_kluster <- data.frame(kluster_eval(data = tmp, 
                              clusters = 2,#known gold standard number of clusters
                              iter_sim = 1,#number of simulation iterations if need be more than 1
                              iter_klust = iter_klust,#iteration for each algorithm
                              algorithm = "Default", #select analysis algorithm from BIC, PAMK, CAL, and AP
                              smpl = smpl))

sjPlot::tab_df(eval_kluster %>% select(starts_with("sim")))
```

#### extract clusters
After evaluating different algorithms we can try to extract the clusters (PAM suggests two which we would like :))
```{r}
out_hkmeans <- factoextra::hkmeans(tmp, 2)
factoextra::fviz_cluster(out_hkmeans)
```

#### visualize klustering
```{r}
kluster_vis = factor(out_hkmeans$cluster, labels = c("clust1", "clust2"))

ggplot(dat)+
  geom_point(data = raw, aes(x=SDO_pos, 
                             y= SDO_neg,
                             colour=kluster_vis),
             size=3,alpha=0.3)+
  ggtitle("") +
  theme_bw() +
  theme(panel.grid.major.y = element_line(colour = "gray"),
        panel.grid.minor.y = element_blank(),
        axis.line = element_line(size=0.5, colour = "black"),
        panel.border = element_blank(), panel.background = element_blank(),
        plot.title = element_text(size = 14, face = "bold"),
        text=element_text(face = "bold"),
        axis.text.x=element_text(colour="black", size = 10, face="plain"),
        axis.text.y=element_text(colour="black", size = 10, face="plain"),
        legend.position="bottom")
```

#### find improbable klusters
```{r}
tmp <- data.frame(table(out_hkmeans$cluster))
tmp$Perc <- tmp$Freq / sum(tmp$Freq) * 100
colnames(tmp)[1] <- c("Kluster")
sjPlot::tab_df(tmp)

# get percentage of datapoints within each kluster
prop_cluster <- prop.table(table(out_hkmeans$cluster))

# check whether datapoints smaller than specified alpha
cut_off <- c(0.05, 0.005)
for (val in cut_off) {
  print(paste("Cut-off:", val, sep = " "))
  print(prop_cluster < val)
}
```

## Prepare scales
### Need Measures
Similar to Gerber, Chang, Reimel (2016), we do not find a four factor solution. We do, however, observe a very similar two-factor soluation; similar to them loading on the wording positive/ negatively worded items.
```{r}
# select relevant vars
tmp <- df %>%
  select(contains("Need_") & !contains("_DO_"))

# get descriptives
sjPlot::tab_df(psych::describe(tmp), show.rownames = T)
pairs.panels.new(tmp)

# confirmatory factor analysis
#correlated four factor solution, marker method
model <- 'f1_blng =~ Need_Disc + Need_Rej + Need_Outside
          f2_estem =~ Need_Good + Need_Insecure + Need_Liked
          f3_mean =~ Need_Invisible + Need_Important + Need_Useful
          f4_ctrl = ~ Need_Control + Need_Pow + Need_Signif
         ' 
facAna <- cfa(model, data=tmp) 
summary(facAna,fit.measures=TRUE,standardized=TRUE)

semPlot::semPaths(facAna, "std")

# exploratory factor analysis
psych::fa.parallel(tmp, fm = "minres", fa = "fa")

res_fa <- psych::fa(tmp, nfactors = 2, rotate = "varimax", fm = "minres")
print(res_fa$loadings, cutoff = 0.3)
rm(tmp, model, facAna, res_fa)

# positive worded needs
tmp <- df %>%
  select(Need_Good, Need_Liked, Need_Important, Need_Useful, Need_Control, Need_Pow, Need_Signif)
scoreItems(keys = c(1,1,1,1,1,1,1), items = tmp, min = min(tmp[1]), max = max(tmp[1]))
df$needs_pos <- scoreItems(keys = c(1,1,1,1,1,1,1), items = tmp, min = min(tmp[1]), max = max(tmp[1]))$scores 

# negative worded needs
tmp <- df %>%
  select(Need_Disc, Need_Rej, Need_Outside, Need_Insecure, Need_Invisible)
scoreItems(keys = c(1,1,1,1,1), items = tmp, min = min(tmp[1]), max = max(tmp[1]))
df$needs_neg <- scoreItems(keys = c(1,1,1,1,1), items = tmp, min = min(tmp[1]), max = max(tmp[1]))$scores 
```

### Behavioral Intentions
The no fly zone item seems to be seen as non-violent. Three factor solution does not work too well.
```{r}
# select relevant vars
tmp <- df %>%
  select(contains("viol_ukr_") & !contains("_DO_"),
         contains("phys_Ukr_") & !contains("_DO_"),
         contains("nonviol_Ukr_") & !contains("_DO_"))

# get descriptives
sjPlot::tab_df(psych::describe(tmp), show.rownames = T)
pairs.panels.new(tmp)

# we remove no intervention as different methodologically
tmp <- tmp %>%
  select(!nonviol_Ukr_noIntervene)

# confirmatory factor analysis
#correlated four factor solution, marker method
model <- 'f1_violent =~ viol_ukr_noFlyZone + viol_ukr_strike + viol_ukr_specops
          f2_nonViol =~ nonviol_Ukr_diplo + nonviol_Ukr_sanction + nonviol_Ukr_finance
          f3_phys =~ phys_Ukr_corridor + phys_Ukr_safeZone + phys_Ukr_blackout
         ' 
facAna <- cfa(model, data=tmp) 
summary(facAna,fit.measures=TRUE,standardized=TRUE)

semPlot::semPaths(facAna, "std")

# exploratory factor analysis
psych::fa.parallel(tmp, fm = "minres", fa = "fa")

res_fa <- psych::fa(tmp, nfactors = 2, rotate = "varimax", fm = "minres")
print(res_fa$loadings, cutoff = 0.4)
rm(tmp, model, facAna, res_fa)

# violent factor
tmp <- df %>%
  select(viol_ukr_strike, viol_ukr_specops)
scoreItems(keys = c(1,1), items = tmp, min = min(tmp[1]), max = max(tmp[1]))
df$help_violent <- scoreItems(keys = c(1,1), items = tmp, min = min(tmp[1]), max = max(tmp[1]))$scores 

# non-violent factor
tmp <- df %>%
  select(nonviol_Ukr_diplo, nonviol_Ukr_sanction, nonviol_Ukr_finance, phys_Ukr_corridor, phys_Ukr_safeZone, phys_Ukr_blackout, phys_Ukr_provWeap)
scoreItems(keys = c(1,1,1,1,1,1,1), items = tmp, min = min(tmp[1]), max = max(tmp[1]))
df$help_nonviolent <- scoreItems(keys = c(1,1,1,1,1,1,1), items = tmp, min = min(tmp[1]), max = max(tmp[1]))$scores 
```

### Rationalizations
```{r}
# select relevant vars
tmp <- df %>%
  select(contains("ratio_") & !contains("_DO_"))

# get descriptives
sjPlot::tab_df(psych::describe(tmp), show.rownames = T)
pairs.panels.new(tmp)

scoreItems(keys = c(1,1,1), items = tmp, min = min(tmp[1]), max = max(tmp[1]))
df$ratio <- scoreItems(keys = c(1,1,1), items = tmp, min = min(tmp[1]), max = max(tmp[1]))$scores
rm(tmp)

```

### ProSocial Intentions
```{r}
# select relevant vars
tmp <- df %>%
  select(contains("proIn_") & !contains("_DO_"))

# get descriptives
sjPlot::tab_df(psych::describe(tmp), show.rownames = T)
pairs.panels.new(tmp)

scoreItems(keys = c(1,1,1,1), items = tmp, min = min(tmp[1]), max = max(tmp[1]))
df$proIn <- scoreItems(keys = c(1,1,1,1), items = tmp, min = min(tmp[1]), max = max(tmp[1]))$scores
rm(tmp)
```

### Disempowerment
```{r}
# select relevant vars
tmp <- df %>%
  select(contains("fail") & !contains("_DO_") & !contains("t_"))

# get descriptives
sjPlot::tab_df(psych::describe(tmp), show.rownames = T)
pairs.panels.new(tmp)

scoreItems(keys = c(1,1,1), items = tmp, min = min(tmp[1]), max = max(tmp[1]))
df$fail <- scoreItems(keys = c(1,1,1), items = tmp, min = min(tmp[1]), max = max(tmp[1]))$scores
rm(tmp)
```

### SDO
```{r}
# select relevant vars
tmp <- df %>%
  select(contains("SDO") & !contains("_DO_") & !contains("t_"))

# get descriptives
sjPlot::tab_df(psych::describe(tmp), show.rownames = T)
pairs.panels.new(tmp)

scoreItems(keys = c(-1,1,-1,1), items = tmp, min = min(tmp[1]), max = max(tmp[1]))
df$SDO <- scoreItems(keys = c(-1,1,-1,1), items = tmp, min = min(tmp[1]), max = max(tmp[1]))$scores
rm(tmp)
```

### Christian nationalism
```{r}
# select relevant vars
tmp <- df %>%
  select(contains("chris") & !contains("_DO_") & !contains("t_c"))

# get descriptives
sjPlot::tab_df(psych::describe(tmp), show.rownames = T)
pairs.panels.new(tmp)

scoreItems(keys = c(1,1,1,1,1,1), items = tmp, min = min(tmp[1]), max = max(tmp[1]))
df$christ <- scoreItems(keys = c(1,1,1,1,1,1), items = tmp, min = min(tmp[1]), max = max(tmp[1]))$scores
rm(tmp)
```

### Immigrant prejudice
```{r}
# select relevant vars
tmp <- df %>%
  select(contains("threat_") & !contains("_DO_") & !contains("t_c"))

# get descriptives
sjPlot::tab_df(psych::describe(tmp), show.rownames = T)
pairs.panels.new(tmp)

scoreItems(keys = c(1,1,1,1), items = tmp, min = min(tmp[1]), max = max(tmp[1]))
df$threat <- scoreItems(keys = c(1,1,1,1), items = tmp, min = min(tmp[1]), max = max(tmp[1]))$scores
rm(tmp)
```

### Locomoation and Assesment
#### Together
```{r}
# select relevant vars
tmp <- df %>%
  select(contains("Loc_Ass_") & !contains("_DO_"))

# confirmatory factor analysis
#correlated four factor solution, marker method
model <- 'loco =~ Loc_Ass_01 + Loc_Ass_03 + Loc_Ass_04 + Loc_Ass_05 + Loc_Ass_08 + Loc_Ass_12 + Loc_Ass_14 + Loc_Ass_17 + Loc_Ass_19 + Loc_Ass_20 + Loc_Ass_22 + Loc_Ass_23
          assess =~ Loc_Ass_02 + Loc_Ass_06 + Loc_Ass_07 + Loc_Ass_09 + Loc_Ass_10 + Loc_Ass_11 + Loc_Ass_13 + Loc_Ass_15 + Loc_Ass_16 + Loc_Ass_18 + Loc_Ass_21 + Loc_Ass_24
         ' 
facAna <- cfa(model, data=tmp) 
summary(facAna,fit.measures=TRUE,standardized=TRUE)

semPlot::semPaths(facAna, "std")

# exploratory factor analysis
psych::fa.parallel(tmp, fm = "minres", fa = "fa")

res_fa <- psych::fa(tmp, nfactors = 2, rotate = "varimax", fm = "minres")
print(res_fa$loadings, cutoff = 0.3)
rm(tmp, facAna, res_fa, model)
```

#### Locomotion
```{r}
# Locomotion
tmp <- df %>%
  select(Loc_Ass_01, Loc_Ass_03, Loc_Ass_04, Loc_Ass_05, Loc_Ass_08, Loc_Ass_12, Loc_Ass_14, Loc_Ass_17, Loc_Ass_19, Loc_Ass_20, Loc_Ass_22, Loc_Ass_23)

# get descriptives
sjPlot::tab_df(psych::describe(tmp), show.rownames = T)
pairs.panels.new(tmp)

scoreItems(keys = c(1,1,1,1,1,-1,1,1,1,1,-1,1), items = tmp, min = min(tmp[1]), max = max(tmp[1]))
df$loco <- scoreItems(keys = c(1,1,1,1,1,-1,1,1,1,1,-1,1), items = tmp, min = min(tmp[1]), max = max(tmp[1]))$scores
```

#### Assessment
```{r}
tmp <- df %>%
  select(Loc_Ass_02, Loc_Ass_06, Loc_Ass_07, Loc_Ass_09, Loc_Ass_10, Loc_Ass_11, Loc_Ass_13, Loc_Ass_15, Loc_Ass_16, Loc_Ass_18, Loc_Ass_21,  Loc_Ass_24)

# get descriptives
sjPlot::tab_df(psych::describe(tmp), show.rownames = T)
pairs.panels.new(tmp)

scoreItems(keys = c(-1,1,1,1,-1,1,1,1,1,1,-1,1), items = tmp, min = min(tmp[1]), max = max(tmp[1]))
df$assess <- scoreItems(keys = c(-1,1,1,1,-1,1,1,1,1,1,-1,1), items = tmp, min = min(tmp[1]), max = max(tmp[1]))$scores

rm(tmp)
```

# Analyses
## Preliminary Analyses
```{r}
tmp <- df %>%
  select(needs_pos, needs_neg, fail,
         help_violent, help_nonviolent)

# get descriptives
sjPlot::tab_df(psych::describe(tmp), show.rownames = T)
pairs.panels.new(tmp)
```


# Share Data
```{r}
share <- df %>%
  select(-contains("mTurk"),
         -starts_with("t_"),
         -contains("_DO_"),
         -contains("TEXT"),
         -contains("Date"),
         -contains("Name"),
         -contains("Email"),
         -contains("Location"),
         -contains("User"),
         -contains("_Other"),
         -ExternalReference,
         -ResponseId,
         -Duration__in_seconds_,
         -DistributionChannel,
         -Finished,
         -debrief,
         -Status,
         -IPAddress,
         -Progress,
         -end_positive_how)

haven::write_sav(share, "M:/.00 Research/Datasets/cleaned/2022_03_11_Ukraine-Russia.sav"); rm(share)

```



